{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import funcs\n",
    "import load_data\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import subprocess\n",
    "from time import time\n",
    "import git\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%reload_ext load_data\n",
    "%reload_ext funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_evaluation(dataset='valid', pathologies=['pathologies'], Data='', model='', number_augmentation=3):\n",
    "\n",
    "    def log_results(dataframe, probs_2d_orig, pathologies, MA, dataset):\n",
    "\n",
    "        def add_dataframe_info_columns(df_info, probs_2d, pathologies):\n",
    "\n",
    "            df              = df_info.drop(pathologies,axis=1)\n",
    "            df_temp         = pd.DataFrame(probs_2d_orig, columns=pathologies).set_index(df.index)\n",
    "            df[pathologies] = df_temp[pathologies]\n",
    "\n",
    "            return df\n",
    "\n",
    "        path = f'../../prob_{dataset}.csv'\n",
    "        df = add_dataframe_info_columns(df_info=dataframe, probs_2d=probs_2d_orig, pathologies=pathologies)\n",
    "        df.to_csv(path)\n",
    "        mlflow.log_artifact(path,artifact_path=f'probabilities/{dataset}/')\n",
    "\n",
    "        path = f'../../prob_aug_avg_{dataset}.csv'\n",
    "        pd.DataFrame( MA.probs_avg_2d, columns=Info.pathologies ).to_csv(path)\n",
    "        mlflow.log_artifact(path,artifact_path=f'probabilities/{dataset}/')\n",
    "\n",
    "        path = f'../../uncertainty_{dataset}.csv'\n",
    "        pd.DataFrame( MA.probs_std_2d, columns=Info.pathologies ).to_csv(path)\n",
    "        mlflow.log_artifact(path,artifact_path=f'uncertainties/{dataset}/')\n",
    "\n",
    "\n",
    "        path = f'../../accuracy_orig_{dataset}.csv'\n",
    "        accuracy = np.floor( 1000*np.mean((MA.truth > 0.5) == (probs_2d_orig > 0.5),axis=0) )/ 10\n",
    "        pd.DataFrame( {'accuracy':accuracy, 'pathologies':Info.pathologies} ).set_index('pathologies').to_csv(path)\n",
    "        mlflow.log_artifact(path,artifact_path=f'accuracies/{dataset}/')\n",
    "\n",
    "        path = f'../../accuracy_aug_{dataset}.csv'\n",
    "        accuracy = np.floor( 1000*np.mean((MA.truth > 0.5) == (MA.probs_avg_2d > 0.5),axis=0) )/ 10\n",
    "        pd.DataFrame( {'accuracy':accuracy, 'pathologies':Info.pathologies} ).set_index('pathologies').to_csv(path)\n",
    "        mlflow.log_artifact(path,artifact_path=f'accuracies/{dataset}/')\n",
    "\n",
    "\n",
    "\n",
    "    probs_2d_orig, final_results, MA = funcs.apply_technique_aim_1_2( how_to_treat_nans   = 'ignore',\n",
    "                                                                      data_generator      = Data.generator[dataset],\n",
    "                                                                      data_generator_aug  = Data.generator[dataset + '_aug'],\n",
    "                                                                      model               = model,\n",
    "                                                                      uncertainty_type    = 'std',\n",
    "                                                                      number_augmentation = number_augmentation)\n",
    "\n",
    "    log_results(dataframe     = Data.dataframe[dataset],\n",
    "                probs_2d_orig = probs_2d_orig,\n",
    "                pathologies   = pathologies,\n",
    "                MA            = MA,\n",
    "                dataset       = dataset)\n",
    "\n",
    "\n",
    "def setting_up_gpu():\n",
    "\n",
    "    config = tf.compat.v1.ConfigProto(inter_op_parallelism_threads=5, intra_op_parallelism_threads=5) # , device_count={\"GPU\":1, \"CPU\": 10})\n",
    "    # config.gpu_options.allow_growth = True\n",
    "    # config.log_device_placement = True\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "    return sess\n",
    "\n",
    "\n",
    "def mlflow_setting_up():\n",
    "\n",
    "    server, artifact = funcs.mlflow_settings()\n",
    "    mlflow.set_tracking_uri(server)\n",
    "\n",
    "\n",
    "    \"\"\" Creating/Setting the experiment\n",
    "        Line below should be commented if the experiment is already created\n",
    "        If kept commented during the first run of a new experiment, the set_experiment\n",
    "        will automatically create the new experiment with local artifact storage \"\"\"\n",
    "\n",
    "    experiment_name = 'soft_weighted_MV_aim1_3'\n",
    "\n",
    "    if not client.get_experiment_by_name(experiment_name):\n",
    "        mlflow.create_experiment(name=experiment_name, artifact_location=artifact)\n",
    "\n",
    "    mlflow.set_experiment(experiment_name=experiment_name)\n",
    "\n",
    "    # Starting the MLflow\n",
    "    run = mlflow.start_run() # run_name; run_id\n",
    "    # mlflow.set_tag(f'mlflow.note.content',f'run_id: {run.info.run_id}')\n",
    "\n",
    "    return run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order of pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathologies = [\"No Finding\", \"Enlarged Cardiomediastinum\" , \"Cardiomegaly\" , \"Lung Opacity\" , \"Lung Lesion\", \"Edema\" , \"Consolidation\" , \"Pneumonia\" , \"Atelectasis\" , \"Pneumothorax\" , \"Pleural Effusion\" , \"Pleural Other\" , \"Fracture\" , \"Support Devices\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a ssh-tunnel to server in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "command     = 'ssh -N -L 5000:localhost:5432 artinmajdi@data7-db1.cyverse.org &'\n",
    "ssh_session = subprocess.Popen('exec ' + command, stdout=subprocess.PIPE, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_experiment_name = 'soft_weighted_MV_aim1_3'\n",
    "\n",
    "run_id_models = {     'ResNet50V2':       'e98f3c431281497e8155d7384b11cca9',\n",
    "                      'InceptionV3':      '108673cc2258460d961a1da71942a30d',\n",
    "                      'InceptionResNetV2':'500f8449a371444188ae9fdee950a0c5',\n",
    "                      'EfficientNetB0':   'aa829e405f904b7e865b5cc8f621a0e4',\n",
    "                      'DenseNet121':      'f857040aa1284bdb8b932aacd37379cb',\n",
    "                      'MobileNetV2':      '24c9eb3e84c1407698dd08a174ae9008',\n",
    "                      'ResNet101V2':      '5aed61485804409b8dd9ec5419f26697',\n",
    "                      'DenseNet169':      'afc854bea43e49a08992a2cfb1d94c98',\n",
    "                      'VGG16':            '255bf0aae1e74b228618ea5c3ce0efb5',\n",
    "                      'DenseNet201':      '6f72b8f68de74ea5a7027c0f288e1e28'}\n",
    "\n",
    "run_id_stats_valid = {'ResNet50V2':       '7c50e57cbc574a898f542ebd8603fa6b',\n",
    "                      'InceptionV3':      'a35b54b6a74747df8388d67ba5f1966c',\n",
    "                      'InceptionResNetV2':'00619d5cf0a84d82a68f7c97f4c5f575',\n",
    "                      'EfficientNetB0':   '5969b09160af40339135257e17cc6744',\n",
    "                      'DenseNet121':      '59eb1cb557af457f8846c7dca5e70090',\n",
    "                      'MobileNetV2':      '193ad9cf68374a3db1fdbb4473e37bbd',\n",
    "                      'ResNet101V2':      '3828ffa16106434c9d153341ba5647f3',\n",
    "                      'DenseNet169':      '3aea8516a073408ba17ff1c4aca6d76a',\n",
    "                      'VGG16':            'a6da14800fad4b659c5145ec4874b5ea',\n",
    "                      'DenseNet201':      'c12fb1de7cbd4b5fb6be8bc2a9929a21'}\n",
    "\n",
    "run_id_stats_test = {'ResNet50V2':       '4b853d6dfdf44f73be4031161e8b714c',\n",
    "                     'InceptionV3':      '5351397f046f42a0b698d664dd122a22',\n",
    "                     'InceptionResNetV2':'06eabd82e54745aea0c8258fba710b51',\n",
    "                     'EfficientNetB0':   'fe42bc598fae4f6d94f72bd664200cad',\n",
    "                     'DenseNet121':      'adc231040ccc44f8a835e02d42dcca1d',\n",
    "                     'MobileNetV2':      '4b7f4c085b6e45689ae1b36ef5ada964',\n",
    "                     'ResNet101V2':      '93ba5a71d9aa45e9888f50d1bcefe449',\n",
    "                     'DenseNet169':      '64911772e152421ca6ec01de20b39910',\n",
    "                     'VGG16':            'd970926c29bf4716996204f3206e7a90',\n",
    "                     'DenseNet201':      '5297e4094113432284a3c6f07c4efb1e'}\n",
    "\n",
    "model_names_list = list(run_id_models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up mlflow config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the server config\n",
    "server, artifact = funcs.mlflow_settings()\n",
    "\n",
    "# setting the server uri\n",
    "mlflow.set_tracking_uri(server)\n",
    "\n",
    "# Setting up the experiment\n",
    "experiment_name = 'soft_weighted_MV_aim1_3'\n",
    "mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEASURING_UNCERTAINTY_FOR_EACH_LABELERS = False\n",
    "\n",
    "if MEASURING_UNCERTAINTY_FOR_EACH_LABELERS:\n",
    "\n",
    "    # starting the parent session\n",
    "    j = 1\n",
    "    model_name     = model_names_list[j]\n",
    "    run_id_parent  = run_id_models[model_name]\n",
    "    session_parent = mlflow.start_run(run_id=run_id_parent)\n",
    "\n",
    "    # starting the child session\n",
    "    mode_dataset  = 'train_val'\n",
    "    session_child = mlflow.start_run(run_name=mode_dataset, nested=True)\n",
    "\n",
    "    mlflow.set_tag('mlflow.note.content',f'run_id {session_child.info.run_id}')\n",
    "    mlflow.set_tag('run_id', session_child.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Git commit  (only in Jupyter notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MEASURING_UNCERTAINTY_FOR_EACH_LABELERS:\n",
    "\n",
    "    repo = git.Repo(search_parent_directories=True)\n",
    "    git_commit_hash = repo.head.object.hexsha\n",
    "    print('git commit hash', git_commit_hash)\n",
    "    mlflow.set_tag('mlflow.source.git.commit', git_commit_hash)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Terminal Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GETTING_INPUTS_VIA_TERMINAL = False\n",
    "\n",
    "if GETTING_INPUTS_VIA_TERMINAL:\n",
    "    epochs, batch_size, max_sample, architecture_name, number_augmentation = funcs.reading_terminal_inputs()\n",
    "else:\n",
    "    epochs, batch_size, max_sample, architecture_name, number_augmentation = 3, 40, 1000000, 'DenseNet121', 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset    = 'chexpert' # nih chexpert\n",
    "dir        = '/groups/jjrodrig/projects/chest/dataset/' + dataset + '/'\n",
    "\n",
    "if MEASURING_UNCERTAINTY_FOR_EACH_LABELERS:\n",
    "\n",
    "    RUNNING_NEW_RUN = False\n",
    "\n",
    "    if RUNNING_NEW_RUN:\n",
    "        Data, Info = load_data.load(dir=dir, dataset=dataset, batch_size=batch_size, mode='train_val', max_sample=max_sample)\n",
    "\n",
    "        mlflow.log_param('dataset'     , dataset)\n",
    "        mlflow.log_param('max_sample'  , max_sample)\n",
    "        mlflow.log_param('train count' , len(Data.generator['train'].filenames))\n",
    "        mlflow.log_param('valid count' , len(Data.generator['valid'].filenames))\n",
    "        mlflow.log_param('batch size'  , batch_size)\n",
    "\n",
    "    else:\n",
    "        Data, Info = load_data.load(dir=dir, dataset=dataset, batch_size=batch_size, mode='valid', max_sample=max_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MEASURING_UNCERTAINTY_FOR_EACH_LABELERS:\n",
    "\n",
    "    OPTIMIZE_MODEL = False\n",
    "\n",
    "    if OPTIMIZE_MODEL:\n",
    "        model = funcs.optimize( train_dataset     = Data.data_tf['train'],\n",
    "                                valid_dataset     = Data.data_tf['valid'],\n",
    "                                architecture_name = architecture_name,\n",
    "                                epochs            = epochs,\n",
    "                                Info              = Info,\n",
    "                                dir               = dir)\n",
    "    else:\n",
    "         # NOTE: \"session_child\" might be the \"session_parent\"\n",
    "        model = mlflow.keras.load_model(model_uri=f'runs:/{session_child.info.run_id}/model',compile=False)\n",
    "\n",
    "        model.compile(  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                        loss      = funcs.weighted_bce_loss(Info.class_weights), # tf.keras.losses.binary_crossentropy #\n",
    "                        metrics   = [tf.keras.metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATE = True\n",
    "\n",
    "if EVALUATE and MEASURING_UNCERTAINTY_FOR_EACH_LABELERS:\n",
    "\n",
    "    RUN_ON_VALIDATION = False\n",
    "    RUN_ON_TEST       = True\n",
    "\n",
    "    if RUN_ON_VALIDATION:\n",
    "        Data, Info = load_data.load(dir=dir, dataset=dataset, batch_size=batch_size, mode='valid', max_sample=max_sample)\n",
    "\n",
    "        running_evaluation( dataset             = 'valid',\n",
    "                            pathologies         = Info.pathologies,\n",
    "                            Data                = Data,\n",
    "                            model               = model,\n",
    "                            number_augmentation = number_augmentation)\n",
    "\n",
    "    if RUN_ON_TEST:\n",
    "        Data, Info= load_data.load(dir=dir, dataset=dataset, batch_size=batch_size, mode='test', max_sample=max_sample)\n",
    "\n",
    "        running_evaluation( dataset             = 'test',\n",
    "                            pathologies         = Info.pathologies,\n",
    "                            Data                = Data,\n",
    "                            model               = model,\n",
    "                            number_augmentation = number_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the parent session\n",
    "for j in range(len(model_names_list)):\n",
    "    model_name    = model_names_list[j]\n",
    "    run_id        = run_id_stats_valid[model_name]\n",
    "    session_stats = mlflow.get_run(run_id=run_id)\n",
    "\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    local_dir = f'../../temp2_aim1_3_{model_name}'\n",
    "    os.mkdir(local_dir)\n",
    "    full_path = client.download_artifacts(run_id=run_id, path='', dst_path=local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_stats, prob_stats = {}, {}\n",
    "for j in range(len(model_names_list)):\n",
    "    model_name    = model_names_list[j]\n",
    "\n",
    "    path_std = f'/home/u29/mohammadsmajdi/projects/chest_xray/temp_aim1_3_{model_name}/uncertainty_{model_name}.csv'\n",
    "    path_prob = f'/home/u29/mohammadsmajdi/projects/chest_xray/temp_aim1_3_{model_name}/prob_{model_name}_orig.csv'\n",
    "\n",
    "    std_stats[model_name] = pd.read_csv(path_std)\n",
    "    prob_stats[model_name] = pd.read_csv(path_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, w_hat = {}, {}\n",
    "for j in range(len(model_names_list)):\n",
    "\n",
    "    model_name        = model_names_list[j]\n",
    "\n",
    "    T[model_name]     = 1 - std_stats[model_name].set_index('Unnamed: 0')\n",
    "\n",
    "    w_hat[model_name] = T[model_name].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T['ResNet50V2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(w_hat['ResNet50V2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(w_hat)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_sum = df.sum(axis=1).to_numpy()\n",
    "\n",
    "w_sum_2d = np.zeros(df.shape)\n",
    "for j in range(len(model_names_list)):\n",
    "    w_sum_2d[:,j] = w_sum\n",
    "\n",
    "weights = df / pd.DataFrame(w_sum_2d,index=pathologies,columns=model_names_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights\n",
    "# pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing the child mlflow session\n",
    "mlflow.end_run()\n",
    "\n",
    "# closing the parent mlflow session\n",
    "mlflow.end_run()\n",
    "\n",
    "# closing the ssh session\n",
    "ssh_session.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "97f50b47c5db4a373caba7d351ed0bd803d6a9b66b6e99b50d57389022e4f55d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

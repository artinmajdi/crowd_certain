{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from crowd_certain.utilities import dataset_loader, utils\n",
    "from crowd_certain.utilities.settings import Settings\n",
    "from crowd_certain.utilities.params import DatasetNames\n",
    "from crowd_certain.utilities.utils import AIM1_3, Aim1_3_Data_Analysis_Results, AIM1_3_Plot\n",
    "\n",
    "# Configure seaborn theme\n",
    "sns.set_theme(font_scale=1.1, palette='colorblind', style='darkgrid', context='paper')\n",
    "\n",
    "%reload_ext crowd_certain.utilities.dataset_loader\n",
    "%reload_ext crowd_certain.utilities.utils\n",
    "%reload_ext crowd_certain.utilities.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\u001b[H\u001b[2J\u001b[mtop - 15:12:49 up 6 days,  2:46,  0 users,  load average: 3.97, 1.54, 0.60\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m 363 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   6 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m 357 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m 16.2 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  2.0 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 81.8 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 26343524+\u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 23084059+\u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m  5062132 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m 27532532 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m 25725833+\u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\u001b[7m  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4720 mohamma+  20   0   32.1g   1.1g 109236 R 100.0  0.5   0:09.17 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4721 mohamma+  20   0   32.1g   1.1g 109016 R 100.0  0.5   0:09.19 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4722 mohamma+  20   0   32.1g   1.1g 109032 R 100.0  0.5   0:09.15 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4718 mohamma+  20   0   32.1g   1.1g 109024 R 100.0  0.5   0:09.18 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4719 mohamma+  20   0   32.1g   1.1g 108956 R 100.0  0.5   0:09.19 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3763 mohamma+  20   0    9720   1580   1224 S   0.0  0.0   0:00.01 slurm_scri+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3788 mohamma+  20   0    9716   1608   1212 S   0.0  0.0   0:00.00 bash        \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3809 mohamma+  20   0  382876  58472   8344 S   0.0  0.0   0:03.30 jupyter-no+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 4388 mohamma+  20   0   32.1g   1.3g 274328 S   0.0  0.5   0:05.56 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 4591 mohamma+  20   0  671568  47608   8032 S   0.0  0.0   0:01.23 python3.6   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4746 mohamma+  20   0   69268   2364   1544 R   0.0  0.0   0:00.01 top         \u001b[m\u001b[m\u001b[K\n",
      "\u001b[J\u001b[H\u001b[mtop - 15:12:52 up 6 days,  2:46,  0 users,  load average: 3.97, 1.58, 0.62\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m 17.7 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  0.2 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 82.1 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 26343524+\u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 23060539+\u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m  5297324 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m 27532532 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m 25702315+\u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\n",
      "\u001b[m\u001b[1m 4718 mohamma+  20   0   32.1g   1.1g 109472 R 100.0  0.5   0:12.20 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4719 mohamma+  20   0   32.1g   1.1g 109412 R 100.0  0.5   0:12.20 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4720 mohamma+  20   0   32.1g   1.1g 109480 R 100.0  0.5   0:12.18 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4722 mohamma+  20   0   32.1g   1.1g 109480 R 100.0  0.5   0:12.16 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4721 mohamma+  20   0   32.1g   1.1g 109412 R  99.7  0.5   0:12.19 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 4591 mohamma+  20   0  671568  47608   8032 S   1.0  0.0   0:01.26 python3.6   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4746 mohamma+  20   0   69268   2532   1596 R   0.3  0.0   0:00.02 top         \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3763 mohamma+  20   0    9720   1580   1224 S   0.0  0.0   0:00.01 slurm_scri+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3788 mohamma+  20   0    9716   1608   1212 S   0.0  0.0   0:00.00 bash        \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3809 mohamma+  20   0  382876  58472   8344 S   0.0  0.0   0:03.30 jupyter-no+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 4388 mohamma+  20   0   32.1g   1.3g 274328 S   0.0  0.5   0:05.56 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[J\u001b[?1l\u001b>\u001b[25;1H\n",
      "\u001b[K"
     ]
    }
   ],
   "source": [
    "!top -u mohammadsmajdi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange; font-family:PT Sans Narrow; font-size:1.31em\"> 1 Loading the Data </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- path_all_datasets/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/datasets\n",
      "Loading dataset: banknote (ID: 267) from UCI ML Repository\n",
      "Checking the following paths for dataset banknote:\n",
      "  - /Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/datasets/banknote/banknote.data (exists: False)\n",
      "  - /Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/datasets/banknote/banknote.csv (exists: True)\n",
      "Found dataset in local cache at /Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/datasets/banknote/banknote.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.80730</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.92420</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.01120</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.57180</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.36840</td>\n",
       "      <td>9.6718</td>\n",
       "      <td>-3.96060</td>\n",
       "      <td>-3.16250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>-4.50460</td>\n",
       "      <td>-5.8126</td>\n",
       "      <td>10.88670</td>\n",
       "      <td>-0.52846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>-2.41000</td>\n",
       "      <td>3.7433</td>\n",
       "      <td>-0.40215</td>\n",
       "      <td>-1.29530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.3492</td>\n",
       "      <td>-1.45010</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.8773</td>\n",
       "      <td>6.47740</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.3827</td>\n",
       "      <td>12.39300</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1098 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  true\n",
       "0      3.62160    8.6661  -2.80730 -0.44699     0\n",
       "2      3.86600   -2.6383   1.92420  0.10645     0\n",
       "3      3.45660    9.5228  -4.01120 -3.59440     0\n",
       "4      0.32924   -4.4552   4.57180 -0.98880     0\n",
       "5      4.36840    9.6718  -3.96060 -3.16250     0\n",
       "...        ...       ...       ...      ...   ...\n",
       "1365  -4.50460   -5.8126  10.88670 -0.52846     1\n",
       "1366  -2.41000    3.7433  -0.40215 -1.29530     1\n",
       "1367   0.40614    1.3492  -1.45010 -0.55949     1\n",
       "1368  -1.38870   -4.8773   6.47740  0.34179     1\n",
       "1370  -3.56370   -8.3827  12.39300 -1.28230     1\n",
       "\n",
       "[1098 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the config.json file\n",
    "config_path = '../config.json'  # Adjust this path if needed\n",
    "with open(config_path, 'r') as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "# Create a Settings object from the config file\n",
    "config = Settings(**config_dict)\n",
    "\n",
    "data, feature_columns = dataset_loader.load_dataset(dataset_name=DatasetNames.BANKNOTE, config=config)\n",
    "\n",
    "data['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange; font-family:PT Sans Narrow; font-size:1.3em\"> 1. More detailed version. Repeating the experiments for only 20 workers => to measure confidence score </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 1.1 Measuring prob/uncertainties </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARLS = {'num_labelers': 10,\n",
    "        'low_dis':      0.3,\n",
    "        'high_dis':     0.9}\n",
    "\n",
    "predicted_labels, uncertainty, true_labels, labelers_strength = funcs.apply_technique_aim_1_3( data = data,\n",
    "                                                                                               ARLS = ARLS,\n",
    "                                                                                               num_simulations = 20,\n",
    "                                                                                               feature_columns = feature_columns)\n",
    "\n",
    "labels_all_workers         = predicted_labels['test']['mv']\n",
    "uncertainty_all_workers    = uncertainty['test']\n",
    "truth                      = true_labels['test'].truth\n",
    "\n",
    "uncertainty['test'].head(3).append(labelers_strength.T).round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 1.2 Measuring weights for each labeler </span>\n",
    "\n",
    "***\n",
    "<span style=\"color:grey; font-family:PT Sans narrow; font-size:1.3em\"> 1.2.1 First Method: </span>\n",
    "\n",
    "$ T_{x,a,j} = 1 - u_{j} $\n",
    "\n",
    "***\n",
    "<span style=\"color:grey; font-family:PT Sans narrow; font-size:1.3em\"> 1.2.2 Second Method: </span>\n",
    "\n",
    "$ T_{x,a,j} = \\begin{array}{cc} 1 - u_{j} & y_{a,j} = y'_{j}  \\\\ 0 & y_{a,j} \\neq y'_{j} \\end{array} $\n",
    "\n",
    "***\n",
    "\n",
    "<span style=\"color:grey; font-family:PT Sans narrow; font-size:1.3em\"> 1.2.3 Measuring average weight </span>\n",
    "\n",
    "$ \\hat{w}_{a,j} = \\frac {1}{N} \\sum_{x} T_{x,a,j}$\n",
    "\n",
    "$ w_{a,j} = \\frac {\\hat{w}_{a,j}} {\\sum_{a=1}^{L} \\hat{w}_{a,j}} $\n",
    "\n",
    "***\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 1.3 Weighted majority voting </span>\n",
    "\n",
    "\n",
    "<span style=\"color:grey; font-family:PT Sans narrow; font-size:1.3em\"> 1.3.1 Applying the weights to predicted probabilities </span>\n",
    "\n",
    "$ \\hat{p}^{prob}_{j} = \\sum_{a=1}^{L} p_{a,j} * w_{a,j} $\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:grey; font-family:PT Sans narrow; font-size:1.3em\"> 1.3.2 Applying the weights to predicted labels </span>\n",
    "\n",
    "$ \\hat{p}^{binary}_{j} = \\sum_{a=1}^{L} y_{a,j} * w_{a,j}$ where $y_{a,j} = (p_{a,j} > 0.5) $\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, prob_weighted = funcs.aim1_3_measuring_weights( labels_all_workers=labels_all_workers, uncertainty_all_workers=uncertainty_all_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:grey; font-family:PT Sans narrow; font-size:1.3em\"> 1.3.3 Measuring the weighted MV using only the measured weights (without confidence scores) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measuring the new accuracies\n",
    "acc2 = ( (prob_weighted > 0.5).T == truth ).mean(axis=1)\n",
    "acc2['num_labelers'] = ARLS['num_labelers']\n",
    "\n",
    "accuracy2 = pd.DataFrame( {'accuracy': acc2}).T.set_index('num_labelers')\n",
    "\n",
    "accuracy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, acc = funcs.aim1_3_measure_confidense_score(delta=labels_all_workers, weights=weights, conf_score_strategy=1, num_labelers=ARLS['num_labelers'], truth=true_labels['test'].truth)\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc2 = ((F1.method1>0.5) == (truth > 0.5) ).mean(axis=0)\n",
    "# acc2\n",
    "# truth\n",
    "# F1.method1>0.5\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange; font-family:PT Sans Narrow; font-size:1.3em\"> 2. Benchmark </span>\n",
    "\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 2.1 Overall quality of different workers </span>\n",
    "\n",
    "\n",
    "Estimating the overall qualities of different workers is not a new research topic in the crowdsourcing learning community. To the best of the authors’ knowledge, there exist many state-of-the-art algorithms, such as Dawid–Skene [1], ZenCrowd , KOS [9], and DEW [15, 23]. However, none of them exploit feature vectors of instances, which makes it impossible to take full advantage of the statistical characteristics of the available data when evaluating the label qualities. According to the observation by [30], in traditional supervised learning, there exists a schema to exhibit the relationship between data features and the ground-truth labels. For example, suppose there exists a high-quality worker; the data schema will be well-inherited in their labels, because the difference between their labels and ground-truth labels is small. Meanwhile, suppose there exists a low-quality worker, the data schema may be broken because their labels will be very different from the ground-truth labels. Therefore, we can estimate the overall quality of a worker by evaluating how well the schema is inherited in their labels. Specifically, we can first extract all training instances’ feature vectors and the corresponding crowd labels provided by the jth worker to form a new single-label data set. Then, we use tenfold cross-validation to evaluate the classification accuracy of a classifier. In theory, this classifier can be any classifier. Finally, we define the overall quality of the jth worker as the classification accuracy of the built classifier. The detailed formula can be expressed as\n",
    "\n",
    "\n",
    "$ \\tau_{a} = \\frac {\\sum_{i=1}^{n} \\delta \\Big( f_{a}(x_{i}) , I_{i,a}  \\Big)}{n} $\n",
    "\n",
    "where n is the size of the extracted data set and $f_{j}(x_{i})$ is the class label of the feature vector $x_{i}$ predicted by the built classifier.\n",
    "\n",
    "***\n",
    "\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 2.2 Specific quality of the $j_{th}$ worker for the $i_{th}$ instance ($s_{ij}$) </span>\n",
    "\n",
    "$ s_{x,a} = \\sum^{a'=L}_{ (a'=1) \\land (a' \\neq a) } \\delta \\Big( l_{x,a},l_{x,a'} \\Big) $\n",
    "\n",
    "***\n",
    "$ \\gamma_{x,a} =\\tau_{x,a}(1 + s_{x,a}^{2}) $\n",
    "\n",
    "***\n",
    "$ w'_{x,a} = \\frac {1} {1 + e^{-\\gamma_{x,a}} } $\n",
    "\n",
    "***\n",
    "$ Z = \\frac {1}{L} \\sum_{a=1}^{L}w'_{x,a}  $\n",
    "\n",
    "‍‍‍``` Z is a normalization constant, which ensures that the sum of all crowd label weights for the ith instance is still equal to m ```\n",
    "\n",
    "***\n",
    "$ w_{x,j} = \\frac {1}{Z} w'_{x,j}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = funcs.measuring_Tao_Weights(delta=predicted_labels['test']['simulation_0'] , true_labels=true_labels['test'].drop(columns=['truth']))\n",
    "\n",
    "# measuring accuracy\n",
    "accuracy2['WMV_Tao'] = ( labels['WMV_Tao'] == true_labels['test'].truth ).mean(axis=0)\n",
    "accuracy2['MV']      = ( labels['MV']      == true_labels['test'].truth ).mean(axis=0)\n",
    "\n",
    "accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange; font-family:PT Sans Narrow; font-size:1.3em\"> 3. Confidense score: _Weighted-soft-MV_ </span>\n",
    "\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 3.1 Measuring the certainty score of majority class $ P_{x,j} $ </span>\n",
    "\n",
    "\n",
    "In actual formula this is divided by weights.sum(axis=1). But because weights sum to 1, its values would be 1.\n",
    "\n",
    "Also pandas automatically transfers the binary values in delta\\[disease\\] to float before doing the multiplication.\n",
    "\n",
    "where $\\delta(y_{a,j},+)$ is $1$ if $y_{a,j}$ is positive (TRUE) otherwise $0$. $\\delta(y_{a,j},-)$ is $1$ if $y_{a,j}$ is negative (FALSE) otherwise $0$\n",
    "\n",
    "$ P_{x,j} = \\frac { \\sum_{a=1}^{L} {ω_{a,j} δ(y_{a,j},+)} } { \\sum_{a=1}^{L} {ω_{a,j} δ(y_{a,j},+)}  +  \\sum_{a=1}^{L} {ω_{a,j} δ(y_{a,j},-)} }$\n",
    "\n",
    "***\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 3.2 Certainty of majority class for both positive & negative labels </span>\n",
    "\n",
    "$F_{x,j} = max \\Big(P_{x,j} , 1-P_{x,j} \\Big)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = funcs.aim1_3_measure_confidense_score(delta=labels_all_workers, weights=weights, conf_score_strategy=1, num_labelers=ARLS['num_labelers'], truth=true_labels['test'].truth)\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <span style=\"color:orange; font-family:PT Sans Narrow; font-size:1.3em\"> 4. Confidense score: _Beta-soft-MV_ </span>\n",
    "\n",
    "> Note: _This is measured only for METHOD1 since it has a higher accuracy_\n",
    "\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 4.1 Measuring the certainty score of majority class  $f_{x,j}^{-+}$ </span>\n",
    "\n",
    "\n",
    "\n",
    "$f^{+}_{x,j}≔1+\\sum_{a=1}^{L}ω_{a,j}  \\delta \\big( y_{a,j},+ \\big) $\n",
    "\n",
    "$f_{x,j}^{-}≔1+\\sum_{a=1}^{L}ω_{a,j}  \\delta \\big( y_{a,j},- \\big) $\n",
    "\n",
    "***\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 4.2 Measuring the regularized incomplete beta function </span>\n",
    "\n",
    "\n",
    "$I_{x} (α,β)=F(x;α,β)=\\frac{ B(x;α,β) }{B(α,β)} $\n",
    "\n",
    "$ bdtrc(k,n,p) = I_{p} \\Big( \\lfloor {k} \\rfloor + 1 , n - \\lfloor {k} \\rfloor \\Big) = \\sum_{j = \\lfloor {k} \\rfloor + 1} ^ {n} \\binom {n}{j}p^{j}(1-p)^{n-j} $\n",
    "\n",
    "> [source](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.bdtrc.html)\n",
    "\n",
    "\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 4.3 Certainty of majority class for both positive & negative labels </span>\n",
    "\n",
    "$F_{x,j} = max(I_{p} , 1-I_{p})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F2 = funcs.aim1_3_measure_confidense_score(delta=labels_all_workers, weights=weights, method=2, num_labelers=ARLS['num_labelers'], truth=true_labels['test'].truth)\n",
    "F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "97f50b47c5db4a373caba7d351ed0bd803d6a9b66b6e99b50d57389022e4f55d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

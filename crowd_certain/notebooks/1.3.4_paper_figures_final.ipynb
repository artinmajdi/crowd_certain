{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T04:03:47.189140100Z",
     "start_time": "2023-12-24T04:03:47.087910300Z"
    },
    "notebookRunGroups": {
     "groupValue": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from crowd_certain.utilities import utils, dataset_loader, params\n",
    "from crowd_certain.utilities.settings import get_settings, Settings\n",
    "import json\n",
    "import pathlib\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- path_all_datasets/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/datasets\n"
     ]
    }
   ],
   "source": [
    "# Load the config.json file\n",
    "config_path = '../config.json'  # Adjust this path if needed\n",
    "with open(config_path, 'r') as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "# Create a Settings object from the config file\n",
    "config = Settings(**config_dict)\n",
    "\n",
    "# Set the dataset you want to load\n",
    "config.dataset.dataset_name = params.DatasetNames.IONOSPHERE  # Change this to any dataset you want\n",
    "\n",
    "# # Load the dataset\n",
    "# print(f\"Loading dataset: {config.dataset.dataset_name.value}\")\n",
    "# data, feature_columns = dataset_loader.load_dataset(config=config)\n",
    "\n",
    "# data['train']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# <span style=\"color:orange; font-family:PT Sans Narrow; font-size:1em\"> Getting the simulation data for all databases </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T21:14:59.248352Z",
     "start_time": "2023-12-13T21:14:59.231871Z"
    }
   },
   "outputs": [],
   "source": [
    "# config = utils.reading_user_input_arguments( dataset_name='mushroom', dataset_mode='read_arff', parallel_processing=True, outputs_mode='calculate')\n",
    "# out_for_visual = utils.OutputsForVisualization(config=config)\n",
    "# out_for_visual.run_for_one_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T21:19:03.913629Z",
     "start_time": "2023-12-13T21:19:01.051935Z"
    },
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: ionosphere (ID: 52) from UCI ML Repository\n",
      "Checking the following paths for dataset ionosphere:\n",
      "  - /Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/datasets/ionosphere/ionosphere.data (exists: False)\n",
      "  - /Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/datasets/ionosphere/ionosphere.csv (exists: True)\n",
      "Found dataset in local cache at /Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/datasets/ionosphere/ionosphere.csv\n",
      "Loading dataset: chess (ID: 22) from UCI ML Repository\n",
      "Checking the following paths for dataset chess:\n",
      "  - /Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/datasets/chess/chess.data (exists: False)\n",
      "  - /Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/datasets/chess/chess.csv (exists: False)\n",
      "Local dataset not found or could not be loaded: Could not find dataset chess in local cache. Checked paths: ['/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/datasets/chess/chess.data', '/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/datasets/chess/chess.csv']\n",
      "Downloading from UCI ML Repository...\n",
      "Saved dataset to local cache at /Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/datasets/chess/chess.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 35)) while a minimum of 1 is required by RandomForestClassifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteTraceback\u001b[39m                           Traceback (most recent call last)",
      "\u001b[31mRemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n           ^^^^^^^^^^^^^^^^\n  File \"/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/utilities/utils.py\", line 1589, in wrapper\n    return args, AIM1_3.core_measurements(data=data, n_workers=args['nl'], config=config, feature_columns=feature_columns, seed=args['seed'], use_parallelization_benchmarks=False)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/utilities/utils.py\", line 1561, in core_measurements\n    preds_all, uncertainties_all, true_labels, workers_strength = aim1_3.aim1_3_meauring_probs_uncertainties()\n                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/utilities/utils.py\", line 1101, in aim1_3_meauring_probs_uncertainties\n    truth, uncertainties, preds = looping_over_all_workers()\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/utilities/utils.py\", line 1061, in looping_over_all_workers\n    update_predicted_labels_all_sims(LB=LB, sim_num=sim_num)\n  File \"/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/utilities/utils.py\", line 964, in update_predicted_labels_all_sims\n    predicted_labels_all_sims[mode][LB] [ f'simulation_{sim_num}' ] = classifier.predict(self.data[mode][self.feature_columns])\n                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 904, in predict\n    proba = self.predict_proba(X)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 946, in predict_proba\n    X = self._validate_X_predict(X)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 638, in _validate_X_predict\n    X = validate_data(\n        ^^^^^^^^^^^^^^\n  File \"/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 2944, in validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/artinmajdi/Documents/GitHubs/PhD/code/submodules/crowd/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1130, in check_array\n    raise ValueError(\nValueError: Found array with 0 sample(s) (shape=(0, 35)) while a minimum of 1 is required by RandomForestClassifier.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m aim1_3 = \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAim1_3_Data_Analysis_Results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/utilities/utils.py:1870\u001b[39m, in \u001b[36mAim1_3_Data_Analysis_Results.update\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1860\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[33m'\u001b[39m\u001b[33mAim1_3_Data_Analysis_Results\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   1861\u001b[39m \u001b[38;5;250m\t\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1862\u001b[39m \u001b[33;03m\tUpdate the internal state with calculated results for all datasets.\u001b[39;00m\n\u001b[32m   1863\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1868\u001b[39m \u001b[33;03m\t\tAim1_3_Data_Analysis_Results: Returns self to allow for method chaining.\u001b[39;00m\n\u001b[32m   1869\u001b[39m \u001b[33;03m\t\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1870\u001b[39m \t\u001b[38;5;28mself\u001b[39m.results_all_datasets  = \u001b[43mAIM1_3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalculate_all_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1871\u001b[39m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/utilities/utils.py:1800\u001b[39m, in \u001b[36mAIM1_3.calculate_all_datasets\u001b[39m\u001b[34m(cls, config)\u001b[39m\n\u001b[32m   1798\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1799\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalculate_all_datasets\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config: \u001b[33m'\u001b[39m\u001b[33mSettings\u001b[39m\u001b[33m'\u001b[39m) -> Dict[params.DatasetNames, ResultComparisonsType]:\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m \t\u001b[38;5;28;01mreturn\u001b[39;00m {dt: \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcalculate_one_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m dt \u001b[38;5;129;01min\u001b[39;00m config.dataset.datasetNames}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/utilities/utils.py:1786\u001b[39m, in \u001b[36mAIM1_3.calculate_one_dataset\u001b[39m\u001b[34m(cls, config, dataset_name)\u001b[39m\n\u001b[32m   1783\u001b[39m aim1_3 = \u001b[38;5;28mcls\u001b[39m(data=data, feature_columns=feature_columns, config=config)\n\u001b[32m   1785\u001b[39m \u001b[38;5;66;03m# getting the outputs\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m outputs = \u001b[43maim1_3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m \u001b[38;5;66;03m# measuring the confidence scores\u001b[39;00m\n\u001b[32m   1789\u001b[39m \u001b[38;5;66;03m# findings_confidence_score = aim1_3.get_confidence_scores(outputs)\u001b[39;00m\n\u001b[32m   1790\u001b[39m \n\u001b[32m   1791\u001b[39m \u001b[38;5;66;03m# measuring the worker strength weight relationship for proposed and Tao\u001b[39;00m\n\u001b[32m   1792\u001b[39m weight_strength_relation = aim1_3.worker_weight_strength_relation(seed=\u001b[32m0\u001b[39m, n_workers=\u001b[32m10\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHubs/PhD/code/submodules/crowd/crowd_certain/utilities/utils.py:1661\u001b[39m, in \u001b[36mAIM1_3.get_outputs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1659\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.simulation.use_parallelization:\n\u001b[32m   1660\u001b[39m \t\u001b[38;5;28;01mwith\u001b[39;00m multiprocessing.Pool(processes=\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m.config.simulation.max_parallel_workers, \u001b[38;5;28mlen\u001b[39m(input_list))) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m \t\tcore_results = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1663\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1664\u001b[39m \tcore_results = [function(args) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m input_list]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py:367\u001b[39m, in \u001b[36mPool.map\u001b[39m\u001b[34m(self, func, iterable, chunksize)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    363\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[33;03m    in a list that is returned.\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py:774\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 35)) while a minimum of 1 is required by RandomForestClassifier."
     ]
    }
   ],
   "source": [
    "aim1_3 = utils.Aim1_3_Data_Analysis_Results(config=config).update()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# <span style=\"color:orange; font-family:PT Sans Narrow; font-size:1em\"> Figures </span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <span style=\"font-family:PT Sans Narrow; font-size:1em\"> Metrics </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T21:15:00.589101Z"
    }
   },
   "outputs": [],
   "source": [
    "aim1_3.figure_metrics_mean_over_seeds_per_dataset_per_worker(metric=params.EvaluationMetricNames.ACC, nl=3, figsize=(12,10), font_scale=1.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T21:15:00.591146Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# df = aim1_3.get_result(metric_name='metrics_all_datasets_workers')\n",
    "aim1_3.figure_metrics_all_datasets_workers(figsize=(13,15), font_scale=1.5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <span style=\"font-family:PT Sans Narrow; font-size:1em\"> Weight Strength Relation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T21:15:00.594583Z"
    }
   },
   "outputs": [],
   "source": [
    "aim1_3.figure_weight_quality_relation(font_scale=1.5, fontsize=15, height=6, aspect=1.3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <span style=\"font-family:PT Sans Narrow; font-size:1em\"> Confidence Scores </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T21:15:00.595460Z"
    }
   },
   "outputs": [],
   "source": [
    "aim1_3.figure_F_heatmap(nl='NL3', metric_name='F_eval_one_worker_all_datasets', figsize=(13,13), font_scale=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T21:15:00.596421Z"
    },
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "aim1_3.figure_F_heatmap( metric_name='F_eval_one_dataset_all_workers', dataset_name=params.DatasetNames.KR_VS_KP, figsize=(13,8), font_scale=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# <span style=\"color:orange; font-family:PT Sans Narrow; font-size:1em\"> Killing mlflow server </span>\n",
    "```bash\n",
    "pkill -f mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T21:15:00.597398Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# closing the child mlflow session\n",
    "# mlflow.end_run()\n",
    "\n",
    "# closing the ssh session\n",
    "# mlflow_setup_main.ssh_session.kill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T21:15:00.598201Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "97f50b47c5db4a373caba7d351ed0bd803d6a9b66b6e99b50d57389022e4f55d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
